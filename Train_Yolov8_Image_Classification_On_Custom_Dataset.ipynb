{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woodsj1206/Train-Yolov8-Image-Classification-On-Custom-Dataset/blob/main/Train_Yolov8_Image_Classification_On_Custom_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0y2vHRgUyFG"
      },
      "source": [
        "#Step 1: Checking GPU Availability\n",
        "Check if a GPU is available in your Google Colab environment. A GPU can significantly accelerate the training process of deep learning models like YOLOv8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S75OM8X7IH7"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcCLxEyWAot"
      },
      "source": [
        "#Step 2: Unzipping Dataset Files\n",
        "Unzip the dataset file containing images. These files are typically compressed to save space and are now being extracted for use in training the YOLOv8 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szt5QH1vSwR_"
      },
      "outputs": [],
      "source": [
        "# Unzip the zip file containing the images\n",
        "!unzip -q 'REPLACE_WITH_YOUR_IMAGE_ZIP_FILE_PATH' -d '/content/images'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoScN3sjXQmt"
      },
      "source": [
        "#Step 3: Installing Ultralytics\n",
        "Install Ultralytics to work with YOLO models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5AMobU32Z-E"
      },
      "outputs": [],
      "source": [
        "# Install Ultralytics library\n",
        "!pip install ultralytics\n",
        "\n",
        "# Import necessary modules from Ultralytics\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFjeGMT4X27V"
      },
      "source": [
        "#Step 4: Mounting Google Drive\n",
        "Mount Google Drive to the Colab environment, enabling access to files stored in your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dob4YRhec9Fm"
      },
      "outputs": [],
      "source": [
        "# Import the drive module from google.colab\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to '/content/Google_Drive'\n",
        "drive.mount('/content/Google_Drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01fjuyyHZ98E"
      },
      "source": [
        "#Step 5: Define Root Directory and Create Subdirectories\n",
        "Define the root directory for your project and create necessary subdirectories to organize your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBHfolzSdnR5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Prompt user for the path\n",
        "PATH = input(\"Enter the desired path: \")\n",
        "\n",
        "ROOT_DIR = f'/content/Google_Drive/MyDrive/{PATH}'\n",
        "\n",
        "# Create directory for data\n",
        "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
        "\n",
        "# Create directory for trainig and validation\n",
        "DATA_VAL_DIR = os.path.join(DATA_DIR, 'val')\n",
        "DATA_TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
        "\n",
        "# Create directory for testing\n",
        "TESTING_DIR = os.path.join(ROOT_DIR, 'testing')\n",
        "\n",
        "# Create the directories if the root directory doesn't exist\n",
        "if not os.path.exists(ROOT_DIR):\n",
        "    os.makedirs(ROOT_DIR)\n",
        "\n",
        "    os.makedirs(DATA_DIR)\n",
        "    os.makedirs(DATA_VAL_DIR)\n",
        "    os.makedirs(DATA_TRAIN_DIR)\n",
        "\n",
        "    os.makedirs(TESTING_DIR)\n",
        "\n",
        "    print(f\"Root directory '{ROOT_DIR}' created successfully.\")\n",
        "else:\n",
        "    print(f\"Root directory '{ROOT_DIR}' already exists.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjnBrJwNpaZv"
      },
      "source": [
        "#Step 6: Organize Dataset for Training and Validation\n",
        "Organize the dataset by moving images and splitting them into separate directories for training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo3wB7Ueai8s"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Replace placeholder with the actual path to the folder containing subfolders of images\n",
        "PARENT_FOLDER_PATH = 'REPLACE_WITH_YOUR_FOLDER_PATH'\n",
        "\n",
        "# Get list of image folders\n",
        "image_folders = os.listdir(PARENT_FOLDER_PATH)\n",
        "\n",
        "for folder in image_folders:\n",
        "    # Create directories for validation and training data\n",
        "    val_dir = os.path.join(DATA_VAL_DIR, folder)  # Validation directory path\n",
        "    train_dir = os.path.join(DATA_TRAIN_DIR, folder)  # Training directory path\n",
        "\n",
        "    os.makedirs(val_dir)  # Create validation directory\n",
        "    os.makedirs(train_dir)  # Create training directory\n",
        "\n",
        "    images_path = os.path.join(PARENT_FOLDER_PATH, folder)\n",
        "\n",
        "    # Get list of image files contained in a folder\n",
        "    image_files = os.listdir(images_path)\n",
        "\n",
        "    # Determine the number of files for the training set\n",
        "    train_count = int(len(image_files) * 0.7)  # 70% of data used for training, 30% used for validation\n",
        "\n",
        "    # Move files to the training directory\n",
        "    for file in image_files[:train_count]:\n",
        "        shutil.move(os.path.join(images_path, file), os.path.join(train_dir, file))\n",
        "\n",
        "    # Move files to the validation directory\n",
        "    for file in image_files[train_count:]:\n",
        "        shutil.move(os.path.join(images_path, file), os.path.join(val_dir, file))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn93_5WkqiNm"
      },
      "source": [
        "#Step 7: Train the YOLOv8 Model\n",
        "Train the YOLOv8 model using the provided dataset configuration and save the training results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyZJX6PVfE7J"
      },
      "outputs": [],
      "source": [
        "# Load a pre-trained YOLOv8 model\n",
        "model = YOLO('yolov8n-cls.pt')\n",
        "\n",
        "# Train the model using the provided dataset configuration\n",
        "model_results = model.train(data=DATA_DIR, epochs=20)\n",
        "\n",
        "# Save the training results\n",
        "shutil.make_archive(base_dir='/content/runs', root_dir='/content/runs', format='zip', base_name=f'{ROOT_DIR}/runs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJO_S4RYq4at"
      },
      "source": [
        "#Step 8: View Training Results\n",
        "Display the training results and the confusion matrix generated during the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVZypTYk6T85"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "# Display the training results\n",
        "Image('runs/classify/train/results.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv6luQVEAVHK"
      },
      "outputs": [],
      "source": [
        "# Display the confusion matrix\n",
        "Image('runs/classify/train/confusion_matrix.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUFhvf6LsUIt"
      },
      "source": [
        "#Step 9: Process Image Files\n",
        "Process image files using the trained YOLOv8 model and save them in the Colab environment.\n",
        "\n",
        "**NOTE:** Ensure you have uploaded your image files to the testing folder before proceeding with this step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YojVvRieRw3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define the directory where you want to save the images\n",
        "OUTPUT_DIR = '/content/output'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Path to the trained YOLO model file\n",
        "model_file = \"/content/runs/classify/train/weights/best.pt\"\n",
        "\n",
        "# Load the YOLO model\n",
        "model = YOLO(model_file)\n",
        "\n",
        "# List all files in the testing directory\n",
        "files = os.listdir(TESTING_DIR)\n",
        "\n",
        "for image_file in files:\n",
        "    # Construct the full path to the image file\n",
        "    image_path = os.path.join(TESTING_DIR, image_file)\n",
        "\n",
        "    # Load image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Get the height and width of the image\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Perform inference using the model\n",
        "    results = model.predict(image)\n",
        "\n",
        "    # Get class names from the model's output\n",
        "    names = results[0].names\n",
        "\n",
        "    # Get probabilities of each class\n",
        "    probabilities = results[0].probs.data.tolist()\n",
        "\n",
        "    # Get the index of the class with the highest probability\n",
        "    top_prediction_index = np.argmax(probabilities)\n",
        "\n",
        "    # Format label with class name and confidence score\n",
        "    label = f'{names[top_prediction_index]}: {probabilities[top_prediction_index]:.2f}'\n",
        "\n",
        "    # Scale font size and location based on image size\n",
        "    font_scale = min(height, width) / 1000\n",
        "    thickness = max(1, int(min(height, width) / 1000))\n",
        "\n",
        "    # Define text size and baseline to calculate the rectangle size\n",
        "    (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)\n",
        "    text_baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)[1]\n",
        "\n",
        "    location = (0, text_height + text_baseline)\n",
        "\n",
        "    # Define rectangle coordinates\n",
        "    rectangle_start = (location[0], location[1] - text_height - text_baseline)\n",
        "    rectangle_end = (location[0] + text_width, location[1] + text_baseline)\n",
        "\n",
        "    # Draw filled rectangle behind the text\n",
        "    cv2.rectangle(image, rectangle_start, rectangle_end, (255, 0, 0), cv2.FILLED)\n",
        "\n",
        "    # Put text on the image with the detected label\n",
        "    cv2.putText(image, label, location, cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)\n",
        "\n",
        "    # Display the image with the detected label\n",
        "    output_file = os.path.join(OUTPUT_DIR, image_file)  # Output file path\n",
        "    cv2.imwrite(output_file, image)  # Save the modified image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HsCjZQ364Fm"
      },
      "source": [
        "#Step 10: Display Processed Images\n",
        "Use IPython.display to display the processed images within the Colab environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iImN_24m63zX"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "# List all files in the output directory\n",
        "output_images = os.listdir(OUTPUT_DIR)\n",
        "\n",
        "for image in output_images:\n",
        "    # Construct the full path to the image file\n",
        "    image_path = os.path.join(OUTPUT_DIR, image)\n",
        "\n",
        "    # Display the image using IPython.display\n",
        "    display(Image(image_path))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}